{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sudoku Machine Learning Model\n",
    "\n",
    "In this notebook we will train a machine learning model to solve sudokus\n",
    "\n",
    "## Data preparation\n",
    "\n",
    "The first step is to read and prepare the provided data. The data used for training the model is publicly available on Kaggle under the following URL:\n",
    "\n",
    "https://www.kaggle.com/datasets/bryanpark/sudoku\n",
    "\n",
    "The puzzles are reshaped to 9x9 array since this will be the input format for our model. The solutions will be reshaped to a 81x1 array for macthing the output format of our model.\n",
    "We will also apply normalization on our data to improve the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def prepare_data(file): \n",
    "    data = pd.read_csv(file)\n",
    "\n",
    "    feat_raw = data['quizzes']\n",
    "    label_raw = data['solutions']\n",
    "\n",
    "    feat = []\n",
    "    label = []\n",
    "\n",
    "    # Reshape puzzles to 9x9 array\n",
    "    for i in feat_raw:\n",
    "        x = np.array([int(j) for j in i]).reshape((9,9,1))\n",
    "        feat.append(x)\n",
    "    \n",
    "    # Normalize values\n",
    "    feat = np.array(feat)\n",
    "    feat = feat/9\n",
    "    feat -= .5    \n",
    "    \n",
    "    # Reshape solutions to 81x1 array\n",
    "    for i in label_raw:\n",
    "        x = np.array([int(j) for j in i]).reshape((81,1)) - 1\n",
    "        label.append(x)   \n",
    "    \n",
    "    label = np.array(label)\n",
    "    \n",
    "    # Remove raw data from memory\n",
    "    del(feat_raw)\n",
    "    del(label_raw)    \n",
    "\n",
    "    # Split to 80% training and 20% validation\n",
    "    x_train, x_test, y_train, y_test = train_test_split(feat, label, test_size=0.20)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation\n",
    "\n",
    "In this step, we will create our model. By its nature, a Sudoku has some semantic meaning included and therefore we will use an approach based on Convolutional Neural Network (CNN) with Tensorflow (keras).\n",
    "\n",
    "TODO: Add more description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Conv2D, BatchNormalization, Dense, Flatten, Reshape\n",
    "\n",
    "def get_model():\n",
    "    model = keras.models.Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=(3,3), activation='relu', padding='same', input_shape=(9,9,1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, kernel_size=(1,1), activation='relu', padding='same'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(81*9))\n",
    "    model.add(Reshape((-1, 9)))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    return model\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "We load the data and split to training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = prepare_data('sudoku.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train your own Model\n",
    "\n",
    "In this chapter we will finally train our model. We will introduce a callback function that would reduce the learning rate in case of an unchanging accuracy on the validation set (val_accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback, ReduceLROnPlateau\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "callbacks_list = [reduce_lr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will used the Adam optimizer with an initial learning_rate of 0.001.\n",
    "The model is then initialized and trained with data. From performing several tests I could not notice a severe difference training for more than five epochs.\n",
    "\n",
    "After the training, we save the model so that we can access it later from our web application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-17 14:48:37.585447: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.9185 - accuracy: 0.8299"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-17 14:49:16.060738: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 44s 35ms/step - loss: 0.9182 - accuracy: 0.8301 - val_loss: 0.4958 - val_accuracy: 0.9732 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "1250/1250 [==============================] - 47s 37ms/step - loss: 0.4753 - accuracy: 0.9781 - val_loss: 0.4661 - val_accuracy: 0.9809 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "1250/1250 [==============================] - 47s 38ms/step - loss: 0.4526 - accuracy: 0.9860 - val_loss: 0.4518 - val_accuracy: 0.9859 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "1250/1250 [==============================] - 47s 38ms/step - loss: 0.4368 - accuracy: 0.9928 - val_loss: 0.4412 - val_accuracy: 0.9899 - lr: 0.0010\n",
      "Epoch 5/5\n",
      "1250/1250 [==============================] - 47s 38ms/step - loss: 0.4236 - accuracy: 0.9992 - val_loss: 0.4351 - val_accuracy: 0.9921 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: sudoku.model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: sudoku.model/assets\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "\n",
    "adam = keras.optimizers.Adam(learning_rate=.001)\n",
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer=adam, \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, \n",
    "          validation_data=(x_test,y_test), batch_size=640, \n",
    "          epochs=5, verbose=1, callbacks=callbacks_list)\n",
    "\n",
    "model.save(\"sudoku.model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
